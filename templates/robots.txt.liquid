# ================================
# Robots.txt â€“ SEO Cleanup
# ================================

User-agent: *

# Block duplicate language URLs
Disallow: /en-be/
Disallow: /de-at/

# Block parameter URLs (crawl traps)
Disallow: /*?variant=
Disallow: /*?page=
Disallow: /*?sort=
Disallow: /*?filter=
Disallow: /*&variant=
Disallow: /*&page=
Disallow: /*&sort=
Disallow: /*&filter=

# Block auto-generated collection
Disallow: /collections/all